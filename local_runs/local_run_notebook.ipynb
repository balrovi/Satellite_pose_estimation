{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "178f3d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-03 09:59:39.007685: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch \n",
    "from torch import nn \n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split \n",
    "from torchvision import transforms, models\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from utils import PyTorchSatellitePoseEstimationDataset\n",
    "from submission import SubmissionWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d81822ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIRST TIME SETUP\n",
    "#Change the path to your local SPEED data directory after download from https://kelvins.esa.int/satellite-pose-estimation-challenge/data/\n",
    "DATA_PATH= \"/home/salem/Documents/DLR/Challenge/speed\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ebcbde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SatellitePoseEstimationModel(pl.LightningModule):\n",
    "    def __init__(self, submission = None) :\n",
    "        super().__init__() \n",
    "        initialized_model = models.resnet18(pretrained=True)\n",
    "        num_ftrs = initialized_model.fc.in_features\n",
    "        initialized_model.fc = torch.nn.Linear(num_ftrs, 7)\n",
    "        self.model = initialized_model\n",
    "        self.submission = submission\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.model(x)\n",
    "        \n",
    "    def training_step(self,batch ,batch_idx):\n",
    "        x,y = batch \n",
    "        y_hat = self.model(x)\n",
    "        loss = F.mse_loss(y_hat.float(),y.float())\n",
    "        self.log('step', self.trainer.current_epoch+1)\n",
    "        self.log('losses', {'train': loss})\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x,y = batch \n",
    "        y_hat = self.model(x)\n",
    "        loss = F.mse_loss(y_hat.float(),y.float())\n",
    "        self.log('step', self.trainer.current_epoch+1)\n",
    "        self.log('losses', {'valid': loss})\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(),lr = 0.001)\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        inputs, filenames = batch \n",
    "        outputs = self.model(inputs)\n",
    "        \n",
    "        q_batch = outputs[:, :4].cpu().numpy()\n",
    "        r_batch = outputs[:, -3:].cpu().numpy()\n",
    "    \n",
    "        for filename, q, r in zip(filenames, q_batch, r_batch):\n",
    "            self.submission.append_test(filename, q, r)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5f910ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModule(pl.LightningDataModule) : \n",
    "    def __init__(self, batch_size = 32, num_workers = 8, speed_root=''):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size \n",
    "        #num_workers = 4*gpu_num\n",
    "        self.num_workers = num_workers \n",
    "        self.speed_root = speed_root\n",
    "\n",
    "    def setup(self, stage = None):\n",
    "        #Transforms \n",
    "        data_transforms = transforms.Compose([transforms.Resize((224, 224)),\n",
    "                                              transforms.ToTensor(),\n",
    "                                              transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                                   [0.229, 0.224, 0.225])])\n",
    "        full_dataset = PyTorchSatellitePoseEstimationDataset('train', self.speed_root, data_transforms)\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            self.train_dataset, self.val_dataset = torch.utils.data.random_split(full_dataset, \n",
    "                                                                   [int(len(full_dataset) * .8),\n",
    "                                                                    int(len(full_dataset) * .2)])\n",
    "        if stage == \"test\" or stage is None:\n",
    "            self.test_dataset = PyTorchSatellitePoseEstimationDataset('test', self.speed_root, data_transforms)\n",
    "            self.real_test_dataset = PyTorchSatellitePoseEstimationDataset('realtest', self.speed_root, data_transforms)\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=self.num_workers) \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size, shuffle=True, num_workers=self.num_workers)\n",
    "    def test_dataloader(self):\n",
    "        return [DataLoader(self.test_dataset, batch_size = self.batch_size, num_workers = self.num_workers),\n",
    "                DataLoader(self.test_dataset, batch_size = self.batch_size, num_workers = self.num_workers)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6868696b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name  | Type   | Params\n",
      "---------------------------------\n",
      "0 | model | ResNet | 11.2 M\n",
      "---------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.720    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d690ee49ab2485eba0bb930f637a9a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#TODO: Submission\n",
    "\n",
    "args = {'data-path': DATA_PATH,\n",
    "        'num_workers' : 8,\n",
    "        'batch_size': 32,\n",
    "        'gpus':0,\n",
    "        'max_epochs':2,\n",
    "        'accelerator':'ddp',\n",
    "        'num_nodes': 1}\n",
    "\n",
    "trial_name = f\"first_model_{args['max_epochs']}epochs\"\n",
    "\n",
    "args['logdir'] = f\"./{trial_name}/logs\"\n",
    "\n",
    "os.makedirs(f\"{trial_name}\", exist_ok=True)\n",
    "\n",
    "#     MySubmission = SubmissionWriter()\n",
    "\n",
    "model = SatellitePoseEstimationModel()\n",
    "\n",
    "dm = DataModule(batch_size = args['batch_size'], \n",
    "                num_workers = args['num_workers'], \n",
    "                speed_root = args['data-path'])\n",
    "\n",
    "tb_logger = TensorBoardLogger(args['logdir']) #, name = trial_name)\n",
    "\n",
    "# ------------\n",
    "# training\n",
    "# ------------\n",
    "trainer = pl.Trainer(gpus = args['gpus'], max_epochs = args['max_epochs'], logger=tb_logger) #, plugins=DDPPlugin(find_unused_parameters=False))    \n",
    "trainer.fit(model= model, datamodule = dm)\n",
    "trainer.save_checkpoint(f\"{trial_name}/{trial_name}.ckpt\")\n",
    "\n",
    "# try : \n",
    "#     trainer.fit(model, dm)\n",
    "# except : \n",
    "#     print(\"ERROR : The model stoped training !\")\n",
    "# finally : \n",
    "#     print('Saving model...')\n",
    "#     trainer.save_checkpoint(f\"{trial_name}/{trial_name}.ckpt\")\n",
    "# #         trainer.test(model = model, datamodule = dm)\n",
    "# #         print(MySubmission.test_results)\n",
    "# #         MySubmission.export(out_dir=\"./outputs\", suffix= trial_name)\n",
    "# print('Done!')\n",
    "# print('-'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9453814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-03 13:27:46.490844: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.4.1 at http://localhost:6007/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir ./first_model_2epochs/logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edeb5b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading existinf model : \n",
    "\n",
    "#trial_name = ''\n",
    "# folder_path = f\"./{trial_name}\"\n",
    "# model_file_path = os.path.join(model_path,\"first_model_100epochs.ckpt\")\n",
    "# model = SatellitePoseEstimationModel()\n",
    "# model = model.load_from_checkpoint(model_file_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
